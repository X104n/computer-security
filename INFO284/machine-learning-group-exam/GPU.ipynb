{"cells":[{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":1129,"status":"ok","timestamp":1682953515345,"user":{"displayName":"Stian Munkejord","userId":"15726443218988106585"},"user_tz":-120},"id":"a_pW0g7-2xNf"},"outputs":[],"source":["from matplotlib import pyplot as plt\n","import numpy as np\n","import torch\n","\n","import torchvision\n","from torchvision import datasets, transforms\n","\n","from collections import Counter\n","from torch.utils.data import random_split\n","\n","from torch.utils.data import DataLoader\n","\n","from torchvision import models\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","from torch.utils.data import DataLoader\n","import torch.optim.lr_scheduler as lr_scheduler\n","import time"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1682953516075,"user":{"displayName":"Stian Munkejord","userId":"15726443218988106585"},"user_tz":-120},"id":"Xt-MyJ9k2xNh"},"outputs":[],"source":["seed = 10\n","torch.manual_seed(seed)\n","\n","category_index = 8\n","n_val = 5000\n","\n","data_path = '/cifar-10-batches-py'\n","torch.set_default_dtype(torch.double)"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"BssbU-fM2xNj"},"source":["Function for loading the Cifar10 dataset.\n","\n","The method will have to be run twice.\n","After running the method for the first time we get create a normalizer from the std and mean of the images. The method is then ran for a second time with the normalizer as the preprocessor."]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"2--LqUA12xNm"},"source":["Loading the CIFAR-10 dataset as tensors."]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1329,"status":"ok","timestamp":1682953517399,"user":{"displayName":"Stian Munkejord","userId":"15726443218988106585"},"user_tz":-120},"id":"DSFTluQr2xNn","outputId":"62ca2872-1ad3-4499-bd53-81ffdcf7732c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n"]}],"source":["transformed_cifar10_train_val = datasets.CIFAR10(\n","    data_path,\n","    train=True,\n","    download=True,\n","    transform = transforms.ToTensor()\n",")"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"GHImKsY42xNq"},"source":["Stacking the set of images into a single tensor. We then create a normalizer for the dataset around the mean and standard deviation of the 3 dimensions (height, width channel (color))."]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":21941,"status":"ok","timestamp":1682953539337,"user":{"displayName":"Stian Munkejord","userId":"15726443218988106585"},"user_tz":-120},"id":"kXWLtJMM2xNs"},"outputs":[],"source":["imgs = torch.stack([img for img, _ in transformed_cifar10_train_val])\n","\n","normalizer = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean = imgs.mean(dim=(0, 2, 3)), std = imgs.std(dim=(0, 2, 3)))])"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"LJ49I_w_2xNt"},"source":["Loading the dataset as tensors for training+validation and testing. This time we apply the composition of transforms."]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":1507,"status":"ok","timestamp":1682953540840,"user":{"displayName":"Stian Munkejord","userId":"15726443218988106585"},"user_tz":-120},"id":"KOfaMPHk2xNv"},"outputs":[],"source":["normalized_cifar10_train_val = datasets.CIFAR10(\n","    data_path,\n","    train=True,\n","    download=False,\n","    transform = normalizer\n",")\n","\n","\n","normalized_cifar10_test = datasets.CIFAR10(\n","    data_path,\n","    train=False,\n","    download=False,\n","    transform = normalizer\n",")"]},{"cell_type":"markdown","metadata":{"id":"DrIkLvSNl_nx"},"source":["Plotting image before and after transformation"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":284},"executionInfo":{"elapsed":45,"status":"ok","timestamp":1682953540842,"user":{"displayName":"Stian Munkejord","userId":"15726443218988106585"},"user_tz":-120},"id":"U1McfzXTnTcy","outputId":"d18498fa-a734-4a9e-bd34-246c0c283c9d"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 2 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["img, _ = transformed_cifar10_train_val[1]\n","img_t, _ = normalized_cifar10_train_val[1]\n","\n","# Clip the values between 0 and 1\n","img = np.clip(img, 0, 1)\n","img_t = np.clip(img_t, 0, 1)\n","\n","fig, ax = plt.subplots(1, 2)\n","\n","ax[0].imshow(img.permute(1, 2, 0))\n","ax[0].axis(\"off\")\n","ax[0].set_title(\"Transformed Image\")\n","\n","ax[1].imshow(img_t.permute(1, 2, 0))\n","ax[1].axis(\"off\")\n","ax[1].set_title(\"Normalized Image\")\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"CCl1SY6s2xNx"},"source":["As this is a binary classification problem where we only want to identify whether an image is a ship or not, we can set the labels that are \"ship\" to true. We set all other labels to false."]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"-GAC-KzK2xN1"},"source":["Splitting the training and validation set randomly."]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15908,"status":"ok","timestamp":1682953556709,"user":{"displayName":"Stian Munkejord","userId":"15726443218988106585"},"user_tz":-120},"id":"1O9NaXXd2xN2","outputId":"62dfa48a-3053-4c0a-a78d-18b1104ca371"},"outputs":[{"name":"stdout","output_type":"stream","text":["Size of the train dataset:         45000\n","Size of the validation dataset:    5000\n","Size of the test dataset:          10000\n"]},{"data":{"text/plain":["Counter({8: 4486,\n","         7: 4486,\n","         1: 4512,\n","         6: 4510,\n","         3: 4516,\n","         5: 4487,\n","         4: 4499,\n","         2: 4483,\n","         0: 4518,\n","         9: 4503})"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["n_train = len(transformed_cifar10_train_val)-n_val\n","\n","normalized_cifar10_train_split, normalized_cifar10_val_split = random_split(\n","    normalized_cifar10_train_val,\n","    [n_train, n_val],\n","\n","    generator=torch.Generator().manual_seed(seed)\n",")\n","\n","print(\"Size of the train dataset:        \", len(normalized_cifar10_train_split))\n","print(\"Size of the validation dataset:   \", len(normalized_cifar10_val_split))\n","print(\"Size of the test dataset:         \", len(normalized_cifar10_test))\n","\n","Counter([label for _, label in normalized_cifar10_train_split])"]},{"cell_type":"markdown","metadata":{"id":"PAxEPhDsnoA8"},"source":["Making this a binary clasification problem, where our designated category index is set to 1, and all other categories is set to 0. (The labels)"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":17808,"status":"ok","timestamp":1682953574511,"user":{"displayName":"Stian Munkejord","userId":"15726443218988106585"},"user_tz":-120},"id":"9cJ2L9x5tYgI"},"outputs":[],"source":["train10 = [(img, int(label == category_index)) for img, label in normalized_cifar10_train_split]\n","val10 = [(img, int(label == category_index)) for img, label in normalized_cifar10_val_split]\n","\n","train_loader = DataLoader(train10, batch_size=64, shuffle=False)\n","val_loader = DataLoader(val10, batch_size=64, shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"nm4V0aKRp8To"},"source":["All of the models where found here: https://pytorch.org/vision/0.8/models.html\n","\n","Theese where the most used models, and we use all of them to see what models performes the best"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2986,"status":"ok","timestamp":1682953577492,"user":{"displayName":"Stian Munkejord","userId":"15726443218988106585"},"user_tz":-120},"id":"McQZHj2Ur_MP","outputId":"85539c86-e505-4c27-c430-d7db20fc758e"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_0_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_0_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=GoogLeNet_Weights.IMAGENET1K_V1`. You can also use `weights=GoogLeNet_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ShuffleNet_V2_X1_0_Weights.IMAGENET1K_V1`. You can also use `weights=ShuffleNet_V2_X1_0_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]}],"source":["import torchvision.models as models\n","\n","def modify_for_binary_classification(model):\n","    if isinstance(model, models.ResNet):\n","        model.fc = torch.nn.Linear(model.fc.in_features, 1)\n","    elif isinstance(model, models.AlexNet) or isinstance(model, models.vgg.VGG):\n","        model.classifier[-1] = torch.nn.Linear(model.classifier[-1].in_features, 1)\n","    elif isinstance(model, models.SqueezeNet):\n","        model.classifier[1] = torch.nn.Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))\n","    elif isinstance(model, models.DenseNet):\n","        model.classifier = torch.nn.Linear(model.classifier.in_features, 1)\n","    elif isinstance(model, models.Inception3):\n","        model.AuxLogits.fc = torch.nn.Linear(model.AuxLogits.fc.in_features, 1)\n","        model.fc = torch.nn.Linear(model.fc.in_features, 1)\n","    elif isinstance(model, models.GoogLeNet):\n","        model.fc = torch.nn.Linear(model.fc.in_features, 1)\n","    elif isinstance(model, models.ShuffleNetV2):\n","        model.fc = torch.nn.Linear(model.fc.in_features, 1)\n","    elif isinstance(model, models.MobileNetV2):\n","        model.classifier[1] = torch.nn.Linear(model.classifier[1].in_features, 1)\n","    else:\n","        raise NotImplementedError(\"Unknown model type\")\n","    return model\n","\n","model_list = [\n","    models.resnet18(pretrained=True),\n","    models.alexnet(pretrained=True),\n","    models.squeezenet1_0(pretrained=True),\n","    models.googlenet(pretrained=True),\n","    models.shufflenet_v2_x1_0(pretrained=True),\n","    models.mobilenet_v2(pretrained=True),\n","]"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"hbU8atrq2xN9"},"source":["Loading pre-trained models and modifying the last layer. We are doing binary classification, so we think we only need one node in the final layer."]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"8tGhu8nO2xN-"},"source":["We use Binary Cross Entropy as it should be suitable for binary classification problems (add reasoning and explanation). We use nn.BCEWithLogitsLoss() as it combines the sigmoid activation function and the BCE into a single class.\n","\n","The optimizer we use is Adam, and we will begin with a learning rate of 0.001, just because it is a commonly used learning rate."]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":361,"status":"ok","timestamp":1682953596833,"user":{"displayName":"Stian Munkejord","userId":"15726443218988106585"},"user_tz":-120},"id":"R43qEeWB2xN_","outputId":"a34d4b68-effe-4e01-f4d9-5e58de44c147"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training on device cpu.\n"]}],"source":["loss_function = torch.nn.BCEWithLogitsLoss()\n","\n","device = (torch.device('cuda') if torch.cuda.is_available()\n","          else torch.device('cpu'))\n","print(f\"Training on device {device}.\")"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1682953577495,"user":{"displayName":"Stian Munkejord","userId":"15726443218988106585"},"user_tz":-120},"id":"ZvPz7_8G2xOA"},"outputs":[],"source":["def train(model,loader):\n","  try:\n","    optimizer = optim.Adam(model.parameters(),  lr=0.001)\n","\n","    model.to(device)\n","\n","    num_epochs = 2\n","\n","    model.train()\n","    optimizer.zero_grad(set_to_none=True)\n","    i = 0\n","    for epoch in range(num_epochs):\n","      start_time = time.time()\n","      running_loss = 0\n","\n","      for inputs, labels in loader:\n","        i += 1\n","        print(i)\n","        inputs = inputs.to(device=device)\n","        labels = labels.to(device=device)\n","\n","        outputs = model(inputs).squeeze()\n","        loss = loss_function(outputs, labels.float())\n","        loss.backward()\n","        optimizer.step()\n","        optimizer.zero_grad()\n","\n","        running_loss += loss.item()\n","\n","      end_time = time.time()\n","      epoch_time = end_time - start_time\n","      lossData = running_loss / len(loader)\n","      print(epoch)\n","      printModelInfo(model, epoch, epoch_time, lossData)\n","  except Exception as e:\n","    printModelInfo(model, e=e)\n","\n","def printModelInfo(model, epoch=None, epoch_time=None, lossData=None, e=None):\n","  if(e != None):\n","    print()\n","    print(\"-\"*50)\n","    print(f\"|{'Model: ' + type(model).__name__:^25}|{('Error: ' + str(e)):^25}|\")\n","    return\n","\n","  if(epoch == 0):\n","    modelTitle = \"Model name\"\n","    epochTitle = \"Epoch Nr\"\n","    timeTitle = \"Time (s)\"\n","    lossTitle = \"Loss (%)\"\n","    print()\n","    print(\"-\"*50)\n","    print(f'|{modelTitle:^15}|{epochTitle:^10}|{timeTitle:^10}|{lossTitle:^10}|')\n","    print(\"-\"*50)\n","\n","  modelName = (f'{type(model).__name__}')\n","  epochNr = (f'Nr.{epoch + 1}')\n","  time = (f'{epoch_time:.2f}s')\n","  lossD = (f'{100 * lossData:.2f}%')\n","\n","  print(f'|{modelName:^15}|{epochNr:^10}|{time:^10}|{lossD:^10}|')\n"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":443},"executionInfo":{"elapsed":8954,"status":"error","timestamp":1682953586438,"user":{"displayName":"Stian Munkejord","userId":"15726443218988106585"},"user_tz":-120},"id":"Fi0qr72Pt2hH","outputId":"f1ee6d92-3943-4e08-a737-4b619005e65a"},"outputs":[{"name":"stdout","output_type":"stream","text":["1\n","2\n","3\n","4\n"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-0b5133d8df80>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodify_for_binary_classification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-27-747a9d25b22f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, loader)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    457\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 459\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    460\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["for model in model_list:\n","  model = modify_for_binary_classification(model)\n","  train(model, train_loader)\n","  print(\"-\"*50)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":13,"status":"aborted","timestamp":1682953586442,"user":{"displayName":"Stian Munkejord","userId":"15726443218988106585"},"user_tz":-120},"id":"1PvqVbWuch4m"},"outputs":[],"source":["def compute_accuracy_on_gpu(model, loader):\n","  try:\n","    # set the model to evaluation mode\n","    model.eval()\n","\n","    # Initialize counters for number of correctly and total labeled samples\n","    correct = 0\n","    total = 0\n","\n","    # Turn off gradient computation since we are not training   \n","    with torch.no_grad():\n","        # Iterate over the data loader\n","        for img, labels in loader:\n","            # Move the input and target tensors to the specified device\n","            img = img.to(device=device, dtype=torch.double)\n","            labels = labels.to(device=device)\n","            \n","            # Forward pass through the model to get the outputs\n","            outputs = model(img)\n","\n","            # Apply sigmoid activation function\n","            sigmoid = torch.sigmoid(outputs).squeeze()\n","\n","            # Threshold the outputs to get the predicted class\n","            predicted = (sigmoid > 0.5).long()\n","\n","            # Update the counters for correctly and total labeled samples\n","            total += labels.shape[0]\n","            correct += int((predicted == labels).sum())\n","\n","    # Compute and return the accuracy  \n","    return correct/total\n","  except Exception as e:\n","    return e\n","\n","\n","for model in model_list:\n","  modelName = \"Model: \" + type(model).__name__\n","  trainingAccuracy = compute_accuracy_on_gpu(model, train_loader)\n","\n","  if isinstance(trainingAccuracy, Exception):\n","    print(f\"Error on model {type(model).__name__}\" )\n","    continue\n","  \n","  ValidationAccuracy = compute_accuracy_on_gpu(model, val_loader)\n","\n","  trainString = (f\"Training Accuracy: {100 * trainingAccuracy:.2f}%\")\n","  valString = (f\"Validation Accuracy: {100 * ValidationAccuracy:.2f}%\")\n","\n","  print(f'|{modelName:^25}|{trainString:^30}|{valString:^30}|')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":13,"status":"aborted","timestamp":1682953586443,"user":{"displayName":"Stian Munkejord","userId":"15726443218988106585"},"user_tz":-120},"id":"MUjNd2YfG9pa"},"outputs":[],"source":["'''\n","            # Get the index of the class with the highest score\n","            _, predicted = torch.max(outputs, dim=1)\n","\n","            # Update the counters for correctly and total labeled samples\n","            total += labels.shape[0]\n","            correct += int((predicted == labels).sum())\n","'''"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":0}
