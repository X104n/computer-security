{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T11:38:24.815979Z",
     "start_time": "2023-04-26T11:38:21.820572Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from collections import Counter\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T11:38:24.882060Z",
     "start_time": "2023-04-26T11:38:24.818997Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seed = 10\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "category_index = 8\n",
    "n_val = 5000\n",
    "\n",
    "data_path = '/cifar-10-batches-py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Function for loading the Cifar10 dataset.\n",
    "\n",
    "The method will have to be run twice.\n",
    "After running the method for the first time we get create a normalizer from the std and mean of the images. The method is then ran for a second time with the normalizer as the preprocessor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Loading the CIFAR-10 dataset as tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T11:38:26.111083Z",
     "start_time": "2023-04-26T11:38:24.847204Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transformed_cifar10_train_val = datasets.CIFAR10(\n",
    "    data_path,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform = transforms.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Stacking the set of images into a single tensor. We then create a normalizer for the dataset around the mean and standard deviation of the 3 dimensions (height, width channel (color))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T11:38:35.675460Z",
     "start_time": "2023-04-26T11:38:26.116232Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imgs = torch.stack([img for img, _ in transformed_cifar10_train_val])\n",
    "\n",
    "normalizer = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean = imgs.mean(dim=(0, 2, 3)), std = imgs.std(dim=(0, 2, 3)))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Loading the dataset as tensors for training+validation and testing. This time we apply the composition of transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T11:38:36.841569Z",
     "start_time": "2023-04-26T11:38:35.672347Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normalized_cifar10_train_val = datasets.CIFAR10(\n",
    "    data_path,\n",
    "    train=True,\n",
    "    download=False,\n",
    "    transform = normalizer\n",
    ")\n",
    "\n",
    "\n",
    "transformed_cifar10_test = datasets.CIFAR10(\n",
    "    data_path,\n",
    "    train=False,\n",
    "    download=False,\n",
    "    transform = normalizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "As this is a binary classification problem where we only want to identify whether an image is a ship or not, we can set the labels that are \"ship\" to true. We set all other labels to false."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T11:38:46.307555Z",
     "start_time": "2023-04-26T11:38:36.836447Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_labels = np.array([label for _, label in transformed_cifar10_train_val])\n",
    "train_labels = np.array(train_labels == category_index).astype(int)\n",
    "\n",
    "test_labels = np.array([label for _, label in transformed_cifar10_test])\n",
    "test_labels = np.array(test_labels == category_index).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Splitting the training and validation set randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T11:38:57.649334Z",
     "start_time": "2023-04-26T11:38:46.311634Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the train dataset:         45000\n",
      "Size of the validation dataset:    5000\n",
      "Size of the test dataset:          10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({8: 4486,\n",
       "         7: 4486,\n",
       "         1: 4512,\n",
       "         6: 4510,\n",
       "         3: 4516,\n",
       "         5: 4487,\n",
       "         4: 4499,\n",
       "         2: 4483,\n",
       "         0: 4518,\n",
       "         9: 4503})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_train = len(transformed_cifar10_train_val)-n_val\n",
    "\n",
    "transformed_cifar10_train_split, transformed_cifar10_val_split = random_split(\n",
    "    transformed_cifar10_train_val,\n",
    "    [n_train, n_val],\n",
    "\n",
    "    generator=torch.Generator().manual_seed(seed)\n",
    ")\n",
    "\n",
    "print(\"Size of the train dataset:        \", len(transformed_cifar10_train_split))\n",
    "print(\"Size of the validation dataset:   \", len(transformed_cifar10_val_split))\n",
    "print(\"Size of the test dataset:         \", len(transformed_cifar10_test))\n",
    "\n",
    "Counter([label for _, label in transformed_cifar10_train_split])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Choosing a pre-trained CNN model: we chose ResNet18, which is not trained on Cifar-10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T11:38:57.687871Z",
     "start_time": "2023-04-26T11:38:57.618026Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Loading pre-trained ResNet18 model and modifying the last layer. We are doing binary classification, so we think we only need one node in the final layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T11:38:58.100515Z",
     "start_time": "2023-04-26T11:38:57.618026Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = models.resnet18(weights='ResNet18_Weights.DEFAULT')\n",
    "\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We use Binary Cross Entropy as it should be suitable for binary classification problems (add reasoning and explanation). We use nn.BCEWithLogitsLoss() as it combines the sigmoid activation function and the BCE into a single class.\n",
    "\n",
    "The optimizer we use is Adam, and we will begin with a learning rate of 0.001, just because it is a commonly used learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T11:38:58.118682Z",
     "start_time": "2023-04-26T11:38:58.102520Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(),  lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Time: 487.74 seconds, Loss: -4749724.256392046\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[26], line 23\u001B[0m\n\u001B[0;32m     21\u001B[0m outputs \u001B[39m=\u001B[39m model(inputs)\u001B[39m.\u001B[39msqueeze()\n\u001B[0;32m     22\u001B[0m loss \u001B[39m=\u001B[39m loss_function(outputs, labels\u001B[39m.\u001B[39mfloat())\n\u001B[1;32m---> 23\u001B[0m loss\u001B[39m.\u001B[39;49mbackward()\n\u001B[0;32m     24\u001B[0m optimizer\u001B[39m.\u001B[39mstep()\n\u001B[0;32m     25\u001B[0m optimizer\u001B[39m.\u001B[39mzero_grad()\n",
      "File \u001B[1;32mc:\\ProgramData\\Anaconda3\\envs\\inf265\\lib\\site-packages\\torch\\_tensor.py:396\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    387\u001B[0m \u001B[39mif\u001B[39;00m has_torch_function_unary(\u001B[39mself\u001B[39m):\n\u001B[0;32m    388\u001B[0m     \u001B[39mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    389\u001B[0m         Tensor\u001B[39m.\u001B[39mbackward,\n\u001B[0;32m    390\u001B[0m         (\u001B[39mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    394\u001B[0m         create_graph\u001B[39m=\u001B[39mcreate_graph,\n\u001B[0;32m    395\u001B[0m         inputs\u001B[39m=\u001B[39minputs)\n\u001B[1;32m--> 396\u001B[0m torch\u001B[39m.\u001B[39;49mautograd\u001B[39m.\u001B[39;49mbackward(\u001B[39mself\u001B[39;49m, gradient, retain_graph, create_graph, inputs\u001B[39m=\u001B[39;49minputs)\n",
      "File \u001B[1;32mc:\\ProgramData\\Anaconda3\\envs\\inf265\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    168\u001B[0m     retain_graph \u001B[39m=\u001B[39m create_graph\n\u001B[0;32m    170\u001B[0m \u001B[39m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[0;32m    171\u001B[0m \u001B[39m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    172\u001B[0m \u001B[39m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 173\u001B[0m Variable\u001B[39m.\u001B[39;49m_execution_engine\u001B[39m.\u001B[39;49mrun_backward(  \u001B[39m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    174\u001B[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001B[0;32m    175\u001B[0m     allow_unreachable\u001B[39m=\u001B[39;49m\u001B[39mTrue\u001B[39;49;00m, accumulate_grad\u001B[39m=\u001B[39;49m\u001B[39mTrue\u001B[39;49;00m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import time\n",
    "\n",
    "train_loader = DataLoader(transformed_cifar10_train_split, batch_size=64, shuffle=False)\n",
    "val_loader = DataLoader(transformed_cifar10_val_split, batch_size=64, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    running_loss = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    end_time = time.time()\n",
    "    epoch_time = end_time - start_time\n",
    "    print(f\"Epoch {epoch + 1}, Time: {epoch_time:.2f} seconds, Loss: {running_loss / len(train_loader)}\")\n",
    "    \n",
    "'''\n",
    "model.eval()\n",
    "val_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(inputs).squeeze()\n",
    "        loss = loss_function(outputs, labels.float())\n",
    "        \n",
    "        val_loss += loss.item()\n",
    "\n",
    "        \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "    \n",
    "'''\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate(model, data_loader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs).squeeze()\n",
    "            predictions = (torch.sigmoid(outputs) > 0.5).int()\n",
    "\n",
    "            y_true.extend(labels.tolist())\n",
    "            y_pred.extend(predictions.tolist())\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, pos_label=1, average='binary')\n",
    "    recall = recall_score(y_true, y_pred, pos_label=1, average='binary')\n",
    "    f1 = f1_score(y_true, y_pred, pos_label=1, average='binary')\n",
    "\n",
    "    return accuracy, precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:\n",
      "Accuracy: 0.10\n",
      "Validation accuracy:\n",
      "Accuracy: 0.10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0964"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we use shuffle = False\n",
    "# Because it is easier to check the predictions made.\n",
    "train_loader = torch.utils.data.DataLoader(transformed_cifar10_train_split, batch_size=64, shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(transformed_cifar10_val_split, batch_size=64, shuffle=False)\n",
    "\n",
    "def compute_accuracy(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # We do not want gradients here, as we will not want to update the parameters.\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "\n",
    "            outputs = model(imgs)\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            total += labels.shape[0]\n",
    "            correct += int((predicted == labels).sum())\n",
    "\n",
    "    acc =  correct / total\n",
    "    print(\"Accuracy: {:.2f}\".format(acc))\n",
    "    return acc\n",
    "\n",
    "print(\"Training accuracy:\")\n",
    "compute_accuracy(model, train_loader)\n",
    "print(\"Validation accuracy:\")\n",
    "compute_accuracy(model, val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[22], line 52\u001B[0m\n\u001B[0;32m     50\u001B[0m test_loader \u001B[39m=\u001B[39m DataLoader(transformed_cifar10_test, batch_size\u001B[39m=\u001B[39m\u001B[39m32\u001B[39m, shuffle\u001B[39m=\u001B[39m\u001B[39mFalse\u001B[39;00m)\n\u001B[0;32m     51\u001B[0m model\u001B[39m.\u001B[39mload_state_dict(torch\u001B[39m.\u001B[39mload(\u001B[39m'\u001B[39m\u001B[39mbest_model.pth\u001B[39m\u001B[39m'\u001B[39m))\n\u001B[1;32m---> 52\u001B[0m accuracy, precision, recall, f1 \u001B[39m=\u001B[39m evaluate(model, test_loader)\n\u001B[0;32m     54\u001B[0m \u001B[39mprint\u001B[39m(\u001B[39mf\u001B[39m\u001B[39m\"\u001B[39m\u001B[39mAccuracy: \u001B[39m\u001B[39m{\u001B[39;00maccuracy\u001B[39m}\u001B[39;00m\u001B[39m, Precision: \u001B[39m\u001B[39m{\u001B[39;00mprecision\u001B[39m}\u001B[39;00m\u001B[39m, Recall: \u001B[39m\u001B[39m{\u001B[39;00mrecall\u001B[39m}\u001B[39;00m\u001B[39m, F1 Score: \u001B[39m\u001B[39m{\u001B[39;00mf1\u001B[39m}\u001B[39;00m\u001B[39m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn[22], line 44\u001B[0m, in \u001B[0;36mevaluate\u001B[1;34m(model, data_loader)\u001B[0m\n\u001B[0;32m     41\u001B[0m         y_pred\u001B[39m.\u001B[39mextend(predictions\u001B[39m.\u001B[39mtolist())\n\u001B[0;32m     43\u001B[0m accuracy \u001B[39m=\u001B[39m accuracy_score(y_true, y_pred)\n\u001B[1;32m---> 44\u001B[0m precision \u001B[39m=\u001B[39m precision_score(y_true, y_pred, pos_label\u001B[39m=\u001B[39;49m\u001B[39m1\u001B[39;49m, average\u001B[39m=\u001B[39;49m\u001B[39m'\u001B[39;49m\u001B[39mbinary\u001B[39;49m\u001B[39m'\u001B[39;49m)\n\u001B[0;32m     45\u001B[0m recall \u001B[39m=\u001B[39m recall_score(y_true, y_pred, pos_label\u001B[39m=\u001B[39m\u001B[39m1\u001B[39m, average\u001B[39m=\u001B[39m\u001B[39m'\u001B[39m\u001B[39mbinary\u001B[39m\u001B[39m'\u001B[39m)\n\u001B[0;32m     46\u001B[0m f1 \u001B[39m=\u001B[39m f1_score(y_true, y_pred, pos_label\u001B[39m=\u001B[39m\u001B[39m1\u001B[39m, average\u001B[39m=\u001B[39m\u001B[39m'\u001B[39m\u001B[39mbinary\u001B[39m\u001B[39m'\u001B[39m)\n",
      "File \u001B[1;32mc:\\ProgramData\\Anaconda3\\envs\\inf265\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1954\u001B[0m, in \u001B[0;36mprecision_score\u001B[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001B[0m\n\u001B[0;32m   1825\u001B[0m \u001B[39mdef\u001B[39;00m \u001B[39mprecision_score\u001B[39m(\n\u001B[0;32m   1826\u001B[0m     y_true,\n\u001B[0;32m   1827\u001B[0m     y_pred,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1833\u001B[0m     zero_division\u001B[39m=\u001B[39m\u001B[39m\"\u001B[39m\u001B[39mwarn\u001B[39m\u001B[39m\"\u001B[39m,\n\u001B[0;32m   1834\u001B[0m ):\n\u001B[0;32m   1835\u001B[0m     \u001B[39m\"\"\"Compute the precision.\u001B[39;00m\n\u001B[0;32m   1836\u001B[0m \n\u001B[0;32m   1837\u001B[0m \u001B[39m    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1952\u001B[0m \u001B[39m    array([0.5, 1. , 1. ])\u001B[39;00m\n\u001B[0;32m   1953\u001B[0m \u001B[39m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1954\u001B[0m     p, _, _, _ \u001B[39m=\u001B[39m precision_recall_fscore_support(\n\u001B[0;32m   1955\u001B[0m         y_true,\n\u001B[0;32m   1956\u001B[0m         y_pred,\n\u001B[0;32m   1957\u001B[0m         labels\u001B[39m=\u001B[39;49mlabels,\n\u001B[0;32m   1958\u001B[0m         pos_label\u001B[39m=\u001B[39;49mpos_label,\n\u001B[0;32m   1959\u001B[0m         average\u001B[39m=\u001B[39;49maverage,\n\u001B[0;32m   1960\u001B[0m         warn_for\u001B[39m=\u001B[39;49m(\u001B[39m\"\u001B[39;49m\u001B[39mprecision\u001B[39;49m\u001B[39m\"\u001B[39;49m,),\n\u001B[0;32m   1961\u001B[0m         sample_weight\u001B[39m=\u001B[39;49msample_weight,\n\u001B[0;32m   1962\u001B[0m         zero_division\u001B[39m=\u001B[39;49mzero_division,\n\u001B[0;32m   1963\u001B[0m     )\n\u001B[0;32m   1964\u001B[0m     \u001B[39mreturn\u001B[39;00m p\n",
      "File \u001B[1;32mc:\\ProgramData\\Anaconda3\\envs\\inf265\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1573\u001B[0m, in \u001B[0;36mprecision_recall_fscore_support\u001B[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001B[0m\n\u001B[0;32m   1571\u001B[0m \u001B[39mif\u001B[39;00m beta \u001B[39m<\u001B[39m \u001B[39m0\u001B[39m:\n\u001B[0;32m   1572\u001B[0m     \u001B[39mraise\u001B[39;00m \u001B[39mValueError\u001B[39;00m(\u001B[39m\"\u001B[39m\u001B[39mbeta should be >=0 in the F-beta score\u001B[39m\u001B[39m\"\u001B[39m)\n\u001B[1;32m-> 1573\u001B[0m labels \u001B[39m=\u001B[39m _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n\u001B[0;32m   1575\u001B[0m \u001B[39m# Calculate tp_sum, pred_sum, true_sum ###\u001B[39;00m\n\u001B[0;32m   1576\u001B[0m samplewise \u001B[39m=\u001B[39m average \u001B[39m==\u001B[39m \u001B[39m\"\u001B[39m\u001B[39msamples\u001B[39m\u001B[39m\"\u001B[39m\n",
      "File \u001B[1;32mc:\\ProgramData\\Anaconda3\\envs\\inf265\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1391\u001B[0m, in \u001B[0;36m_check_set_wise_labels\u001B[1;34m(y_true, y_pred, average, labels, pos_label)\u001B[0m\n\u001B[0;32m   1389\u001B[0m         \u001B[39mif\u001B[39;00m y_type \u001B[39m==\u001B[39m \u001B[39m\"\u001B[39m\u001B[39mmulticlass\u001B[39m\u001B[39m\"\u001B[39m:\n\u001B[0;32m   1390\u001B[0m             average_options\u001B[39m.\u001B[39mremove(\u001B[39m\"\u001B[39m\u001B[39msamples\u001B[39m\u001B[39m\"\u001B[39m)\n\u001B[1;32m-> 1391\u001B[0m         \u001B[39mraise\u001B[39;00m \u001B[39mValueError\u001B[39;00m(\n\u001B[0;32m   1392\u001B[0m             \u001B[39m\"\u001B[39m\u001B[39mTarget is \u001B[39m\u001B[39m%s\u001B[39;00m\u001B[39m but average=\u001B[39m\u001B[39m'\u001B[39m\u001B[39mbinary\u001B[39m\u001B[39m'\u001B[39m\u001B[39m. Please \u001B[39m\u001B[39m\"\u001B[39m\n\u001B[0;32m   1393\u001B[0m             \u001B[39m\"\u001B[39m\u001B[39mchoose another average setting, one of \u001B[39m\u001B[39m%r\u001B[39;00m\u001B[39m.\u001B[39m\u001B[39m\"\u001B[39m \u001B[39m%\u001B[39m (y_type, average_options)\n\u001B[0;32m   1394\u001B[0m         )\n\u001B[0;32m   1395\u001B[0m \u001B[39melif\u001B[39;00m pos_label \u001B[39mnot\u001B[39;00m \u001B[39min\u001B[39;00m (\u001B[39mNone\u001B[39;00m, \u001B[39m1\u001B[39m):\n\u001B[0;32m   1396\u001B[0m     warnings\u001B[39m.\u001B[39mwarn(\n\u001B[0;32m   1397\u001B[0m         \u001B[39m\"\u001B[39m\u001B[39mNote that pos_label (set to \u001B[39m\u001B[39m%r\u001B[39;00m\u001B[39m) is ignored when \u001B[39m\u001B[39m\"\u001B[39m\n\u001B[0;32m   1398\u001B[0m         \u001B[39m\"\u001B[39m\u001B[39maverage != \u001B[39m\u001B[39m'\u001B[39m\u001B[39mbinary\u001B[39m\u001B[39m'\u001B[39m\u001B[39m (got \u001B[39m\u001B[39m%r\u001B[39;00m\u001B[39m). You may use \u001B[39m\u001B[39m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1401\u001B[0m         \u001B[39mUserWarning\u001B[39;00m,\n\u001B[0;32m   1402\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate(model, data_loader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs).squeeze()\n",
    "            predictions = (torch.sigmoid(outputs) > 0.5).int()\n",
    "            \n",
    "            y_true.extend(labels.tolist())\n",
    "            y_pred.extend(predictions.tolist())\n",
    "    \n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "    \n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate(model, data_loader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs).squeeze()\n",
    "            predictions = (torch.sigmoid(outputs) > 0.5).int()\n",
    "\n",
    "            y_true.extend(labels.tolist())\n",
    "            y_pred.extend(predictions.tolist())\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, pos_label=1, average='binary')\n",
    "    recall = recall_score(y_true, y_pred, pos_label=1, average='binary')\n",
    "    f1 = f1_score(y_true, y_pred, pos_label=1, average='binary')\n",
    "\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "test_loader = DataLoader(transformed_cifar10_test, batch_size=32, shuffle=False)\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "accuracy, precision, recall, f1 = evaluate(model, test_loader)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1 Score: {f1}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
